{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the data and create auxiliary text files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n headlines: 650\n",
      "252\n",
      "n cities: 24336\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import geonamescache\n",
    "import unidecode\n",
    "import os\n",
    "import sys\n",
    "import difflib\n",
    "\n",
    "filename = \"headlines.txt\"\n",
    "\n",
    "f = open(filename, \"r\")\n",
    "theHeadlines = f.readlines()\n",
    "theHeadlines.sort()\n",
    "f.close()\n",
    "nHeadlines = len(theHeadlines)\n",
    "print(\"n headlines: {}\".format(nHeadlines))\n",
    "\n",
    "f = open(\"headlines-sorted.txt\", \"w\")\n",
    "for k in theHeadlines:\n",
    "    f.write(k)\n",
    "f.close()\n",
    "\n",
    "gc = geonamescache.GeonamesCache()\n",
    "countriesDict = gc.get_countries()\n",
    "print(len(countriesDict))\n",
    "\n",
    "citiesDict = gc.get_cities()\n",
    "nCities = len(citiesDict)\n",
    "print(\"n cities: {}\".format(nCities))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create list of cities with and without special characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "theCities = []\n",
    "for k in citiesDict.keys():\n",
    "    theCities.append(citiesDict[k][\"name\"])\n",
    "theCities.sort()\n",
    "\n",
    "theCitiesNoAccents = []\n",
    "for k in theCities:\n",
    "    theCitiesNoAccents.append(unidecode.unidecode(k))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write auxiliary file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"cityNames.txt\", \"w\")\n",
    "for k in theCities:\n",
    "    f.write(k + \"\\n\")\n",
    "f.close()\n",
    "\n",
    "f = open(\"cityNames-noAccents.txt\", \"w\")\n",
    "for k in theCitiesNoAccents:\n",
    "    f.write(k + \"\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write auxiliary file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "theHeadlinesNoAccents = []\n",
    "for k in theHeadlines:\n",
    "    theHeadlinesNoAccents.append(unidecode.unidecode(k))\n",
    "f = open(\"headlines-noAccents.txt\", \"w\")\n",
    "for k in theHeadlinesNoAccents:\n",
    "    f.write(k)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** \n",
      "--- \n",
      "***************\n",
      "*** 29 ****\n",
      "! BREAKING – Zika in Missoula\n",
      "--- 29 ----\n",
      "! BREAKING - Zika in Missoula\n",
      "***************\n",
      "*** 340 ****\n",
      "! Panama City’s first Zika related death\n",
      "--- 340 ----\n",
      "! Panama City's first Zika related death\n",
      "***************\n",
      "*** 573 ****\n",
      "! Zika alert – Manila now threatened\n",
      "--- 573 ----\n",
      "! Zika alert - Manila now threatened\n",
      "***************\n",
      "*** 590 ****\n",
      "! Zika case recorded in Tunapuna »\n",
      "--- 590 ----\n",
      "! Zika case recorded in Tunapuna >>\n"
     ]
    }
   ],
   "source": [
    "text1 = open(\"headlines-sorted.txt\")\n",
    "text2 = open(\"headlines-noAccents.txt\")\n",
    "sys.stdout.writelines(difflib.context_diff(theHeadlines, theHeadlinesNoAccents, n=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple try to find matches, it obviously is not correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In 650 headlines and 24336 cities we have 1505 matches\n",
      "{4: 53, 1: 216, 7: 12, 2: 192, 3: 98, 6: 17, 0: 24, 5: 27, 8: 7, 10: 1, 9: 1}\n",
      "0:24  1:216  2:192  3:98  4:53  5:27  6:17  7:12  8:7  9:1  10:1  \n"
     ]
    }
   ],
   "source": [
    "headlineCityCandidates = {}\n",
    "n = 0\n",
    "for oneArticle in theHeadlinesNoAccents:\n",
    "    headlineCityCandidates[oneArticle] = []\n",
    "    for oneCity in theCitiesNoAccents:\n",
    "        if oneCity in oneArticle:\n",
    "            n += 1\n",
    "            headlineCityCandidates[oneArticle].append(oneCity)\n",
    "print(\"In {} headlines and {} cities we have {} matches\".format(nHeadlines,\n",
    "        nCities, n))\n",
    "\n",
    "# eval how many headlines had a given amount of matches\n",
    "headlinesCityMatchCount = {}\n",
    "for k in headlineCityCandidates.keys():\n",
    "    n = len(headlineCityCandidates[k])\n",
    "    if n not in headlinesCityMatchCount:\n",
    "        headlinesCityMatchCount[n] = 0\n",
    "    headlinesCityMatchCount[n] += 1\n",
    "print(headlinesCityMatchCount)\n",
    "\n",
    "# to be more legible print in descending order of the matches\n",
    "nOcorrencias = list(headlinesCityMatchCount.keys())\n",
    "nOcorrencias.sort()\n",
    "for k in nOcorrencias:\n",
    "    print(\"{}:{} \".format(k, headlinesCityMatchCount[k]), end=\" \")\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check matches that failed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 24 headlines with no city detected:\n",
      "Carnival under threat in Rio De Janeiro due to Zika outbreak\n",
      "Chikungunya has not Left Pismo Beach\n",
      "Fort Belvoir tests new cure for Hepatitis C\n",
      "Longwood volunteers spreading Zika awareness\n",
      "Louisiana Zika cases up to 26\n",
      "Maka City Experiences Influenza Outbreak\n",
      "More Zika patients reported in Mcallen\n",
      "More people in Huron are infected with Dengue every year\n",
      "More people in Mclean are infected with Hepatitis A every year\n",
      "Outbreak of Zika in Alvorada\n",
      "Outbreak of Zika in Destin\n",
      "Outbreak of Zika in Hutchins\n",
      "Rumors about Influenza Spreading in Dobbs Ferry have been Refuted\n",
      "Schools in Coamo Closed Due to Rhinovirus Outbreak\n",
      "Spike of Hepatitis E Cases in Morehead City\n",
      "Spike of Meningitis Cases in Druid Hills\n",
      "Yulee takes a hit from Spreading Sickness\n",
      "Zika Troubles come to Padre Las Casas\n",
      "Zika arrives in Dangriga\n",
      "Zika case reported in Antioquia\n",
      "Zika case reported in Oton\n",
      "Zika infects pregnant woman in Cebu\n",
      "Zika spreads to La Joya\n",
      "Zika symptoms spotted in Quixere\n"
     ]
    }
   ],
   "source": [
    "print(\"The {} headlines with no city detected:\".format(headlinesCityMatchCount[0]))\n",
    "for k in headlineCityCandidates.keys():\n",
    "    if len(headlineCityCandidates[k]) == 0:\n",
    "        print(k, end=\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check city with largest number of matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 1 headlines where more matches of cities were detected:\n",
      "Lower Hospitalization in Richmond after Mumps Vaccine becomes Mandatory\n",
      "   Match: ['Ho', 'Man', 'Richmond', 'Richmond', 'Richmond', 'Richmond', 'Richmond', 'Richmond', 'Richmond', 'Vac']\n"
     ]
    }
   ],
   "source": [
    "maxOcorrencias = nOcorrencias[-1] # last list item in an ascending sorted list\n",
    "print(\"The {} headlines where more matches of cities were detected:\".format(\n",
    "            headlinesCityMatchCount[maxOcorrencias]))\n",
    "for k in headlineCityCandidates.keys():\n",
    "    if len(headlineCityCandidates[k]) == maxOcorrencias:\n",
    "        print(k, end=\"\")\n",
    "        print(\"   Match: {}\".format(headlineCityCandidates[k]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create list sorted by descending order of city name's length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 10 cities with longer names: ['Chak Two Hundred Forty-nine Thal Development Authority', 'Dolores Hidalgo Cuna de la Independencia Nacional', 'Ampliación San Mateo (Colonia Solidaridad)', 'Licenciado Benito Juárez (Campo Gobierno)', 'Sant Pere, Santa Caterina i La Ribera', 'Nanchital de Lázaro Cárdenas del Río', 'Palikir - National Government Center', 'San Fernando del Valle de Catamarca', 'San Martin Texmelucan de Labastida', \"el Camp d'en Grassot i Gràcia Nova\"]\n",
      "...\n",
      "The 10 cities with shorter names: ['Ōzu', 'Ōzu', 'Bo', 'Ho', 'Of', 'Pô', 'Un', 'Wa', 'Ōi', 'Ūn']\n"
     ]
    }
   ],
   "source": [
    "# using a lambda because it is negative it sorts in descending order\n",
    "theCities.sort(key = lambda city: -len(city)) \n",
    "print(\"The 10 cities with longer names: {}\".format(theCities[0:10]))\n",
    "print(\"...\")\n",
    "print(\"The 10 cities with shorter names: {}\".format(theCities[-10:]))\n",
    "\n",
    "theCitiesNoAccents = []\n",
    "for k in theCities:\n",
    "    theCitiesNoAccents.append(unidecode.unidecode(k).lower())\n",
    "\n",
    "theHeadlinesNoAccents = []\n",
    "for k in theHeadlines:\n",
    "    theHeadlinesNoAccents.append(unidecode.unidecode(k).lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create list of compiled regular expressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "theCitiesNoAccentsRegExpr = []\n",
    "for k in theCitiesNoAccents:\n",
    "    theCitiesNoAccentsRegExpr.append(re.compile(r\"([^a-zA-Z]|^)\" + \n",
    "        k + r\"([^a-zA-Z]|$)\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detect cities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suspect match ignored: Outbreak of Zika in Alvorada -> of\n",
      "Suspect match ignored: Outbreak of Zika in Destin -> of\n",
      "Suspect match ignored: Outbreak of Zika in Hutchins -> of\n",
      "Suspect match ignored: Spike of Hepatitis E Cases in Morehead City -> of\n",
      "Suspect match ignored: Spike of Meningitis Cases in Druid Hills -> of\n",
      "Suspect match ignored: The Spread of Chikungunya in Davidson has been Confirmed -> of\n",
      "37 match failures\n",
      "FAILED: Bronchitis Outbreak in Manhasset\n",
      "FAILED: Chikungunya has not Left Pismo Beach\n",
      "FAILED: Fort Belvoir tests new cure for Hepatitis C\n",
      "FAILED: Greenwich Establishes Zika Task Force\n",
      "FAILED: Gympie Patient in Critical Condition after Contracting Chlamydia\n",
      "FAILED: Hillsborough uses innovative trap against Zika 20 minutes ago\n",
      "FAILED: Longwood volunteers spreading Zika awareness\n",
      "FAILED: Louisiana Zika cases up to 26\n",
      "FAILED: Maka City Experiences Influenza Outbreak\n",
      "FAILED: Malaria Exposure in Sussex\n",
      "FAILED: Martinsville tests new cure for Measles\n",
      "FAILED: Measles Hits Davos\n",
      "FAILED: More Patients in Magnolia are Getting Diagnosed with Malaria\n",
      "FAILED: More Patients in Maynard are Getting Diagnosed with Syphilis\n",
      "FAILED: More people in Boucau are infected with HIV every year\n",
      "FAILED: More people in Huron are infected with Dengue every year\n",
      "FAILED: More people in Oak Brook are infected with Respiratory Syncytial Virus every year\n",
      "FAILED: Outbreak of Zika in Alvorada\n",
      "FAILED: Outbreak of Zika in Destin\n",
      "FAILED: Outbreak of Zika in Hutchins\n",
      "FAILED: Rumors about Influenza Spreading in Dobbs Ferry have been Refuted\n",
      "FAILED: Rumors about Syphilis spreading in Penal have been refuted\n",
      "FAILED: Schools in Coamo Closed Due to Rhinovirus Outbreak\n",
      "FAILED: Spanish Flu Sighted in Antigua\n",
      "FAILED: Spike of Hepatitis E Cases in Morehead City\n",
      "FAILED: Spike of Meningitis Cases in Druid Hills\n",
      "FAILED: The Spread of Chikungunya in Davidson has been Confirmed\n",
      "FAILED: West Nile Virus Outbreak in Saint Johns\n",
      "FAILED: Will Tuberculosis vaccine help Cherry Creek?\n",
      "FAILED: Will West Nile Virus vaccine help Parsons?\n",
      "FAILED: Zika arrives in Dangriga\n",
      "FAILED: Zika case reported in Antioquia\n",
      "FAILED: Zika case reported in Los Fresnos\n",
      "FAILED: Zika case reported in Oton\n",
      "FAILED: Zika infects pregnant woman in Cebu\n",
      "FAILED: Zika spreads to La Joya\n",
      "FAILED: Zika symptoms spotted in Quixere\n",
      "Headline 0: 18 new Zika Cases in Bogota\n",
      " -> Bogotá\n",
      "Headline 50: Cancun hit by Outbreak of Party Fever!\n",
      " -> Cancún\n",
      "Headline 100: Fort Collins Encounters Severe Symptoms of Gonorrhea\n",
      " -> Fort Collins\n",
      "Headline 150: How to Avoid Contaminated Meat when Visiting Basel\n",
      " -> Basel\n",
      "Headline 200: Mad Cow Disease Re-emerges in Chatham\n",
      " -> Chatham\n",
      "Headline 250: More Zika patients reported in Bella Vista\n",
      " -> Bella Vista\n",
      "Headline 300: New Zika Case Confirmed in Sarasota County\n",
      " -> Sarasota\n",
      "Headline 350: Pneumonia Symptoms Spread all over Bloomington\n",
      " -> Bloomington\n",
      "Headline 400: Sangre Grande Residents Recieve Gonorrhea vaccine\n",
      " -> Sangre Grande\n",
      "Headline 450: Student sick in Campinas, Brazil\n",
      " -> Campinas\n",
      "Headline 500: West Nile Virus Exposure in Alpharetta\n",
      " -> Alpharetta\n",
      "Headline 550: Zika Reported in Ilopango\n",
      " -> Ilopango\n",
      "Headline 600: Zika case reported in Reynosa\n",
      " -> Reynosa\n",
      "607 Zika infects pregnant woman in Cebu\n",
      " -> *** NO MATCH\n",
      "Headline 649: Zika: Delhi for strict monitoring\n",
      " -> Delhi\n"
     ]
    }
   ],
   "source": [
    "nFailures = 0\n",
    "headlineIndexes = []\n",
    "nCities = len(theCitiesNoAccentsRegExpr)\n",
    "failedMatches = []\n",
    "for idx in range(nHeadlines):\n",
    "    oneHeadline = theHeadlinesNoAccents[idx]\n",
    "    theMatches = []\n",
    "    for k in range(nCities):\n",
    "        if theCitiesNoAccentsRegExpr[k].search(oneHeadline) != None:\n",
    "            # print(k, oneHeadline, theCities[k])\n",
    "            if theCities[k] == \"Of\":\n",
    "                if \"Of\" not in oneHeadline.strip().split():\n",
    "                    print(\"Suspect match ignored: {} -> of\".format(theHeadlines[idx].strip()))\n",
    "                    continue\n",
    "            theMatches.append(k)\n",
    "            break # we only want the 1st match\n",
    "    headlineIndexes.append(theMatches)\n",
    "    if len(theMatches) == 0:\n",
    "        nFailures += 1\n",
    "        failedMatches.append(theHeadlines[idx])\n",
    "print(\"{} match failures\".format(nFailures))\n",
    "for k in failedMatches:\n",
    "    print(\"FAILED: {}\".format(k), end=\"\")\n",
    "\n",
    "for k in [0, 50, 100, 150, 200, 250, 300, 350, 400, 450, 500, 550, 600, 607, 649]:\n",
    "    if len(headlineIndexes[k]) != 0:\n",
    "        print(\"Headline {}: {} -> {}\".format(k, theHeadlines[k], theCities[headlineIndexes[k][0]]))\n",
    "    else:\n",
    "        print(\"{} {} -> {}\".format(k, theHeadlines[k], \"*** NO MATCH\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create list of cities and countries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 18 new Zika Cases in Bogota -> Bogotá (Colombia)\n",
      "1: 19 new Zika Cases in Sengkang -> Sengkang (Indonesia)\n",
      "2: Alameda Residents Recieve Rabies vaccine -> Alameda (United States)\n",
      "3: Albany Residents Recieve Respiratory Syncytial Virus vaccine -> Albany (Australia)\n",
      "4: Antipolo under threat from Zika Virus -> Antipolo (Philippines)\n",
      "5: Arhus is infested with Bronchitis -> Århus (Denmark)\n",
      "6: Arvada is infested with Syphilis -> Arvada (United States)\n",
      "7: Authorities a Miami -> Miami (United States)\n",
      "8: Authorities are Worried about the Spread of Bronchitis in Silver Spring -> Silver Spring (United States)\n",
      "9: Authorities are Worried about the Spread of Chickenpox in Hemet -> Hemet (United States)\n"
     ]
    }
   ],
   "source": [
    "headlineNoLinebreak = []\n",
    "headlineCity = []\n",
    "headlineCountry = []\n",
    "\n",
    "for k in range(nHeadlines):\n",
    "    headlineNoLinebreak.append(theHeadlines[k].strip())\t\t\n",
    "    if len(headlineIndexes[k]) == 0:\n",
    "        headlineCity.append(None)\n",
    "        headlineCountry.append(None)\n",
    "    else:\n",
    "        headlineCity.append(theCities[headlineIndexes[k][0]])\n",
    "        theCity = gc.get_cities_by_name(theCities[headlineIndexes[k][0]])\n",
    "        theCityDict = theCity[0]\n",
    "        theCityKey = list(theCityDict.keys())[0] \n",
    "        countryCode = theCityDict[theCityKey][\"countrycode\"]\n",
    "        headlineCountry.append(countriesDict[countryCode][\"name\"])\n",
    "\n",
    "for k in range(10):\n",
    "    print(\"{}: {} -> {} ({})\".format(k, theHeadlines[k].strip(),\n",
    "            headlineCity[k], headlineCountry[k]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            headline      countries  \\\n",
      "0                        18 new Zika Cases in Bogota       Colombia   \n",
      "1                      19 new Zika Cases in Sengkang      Indonesia   \n",
      "2           Alameda Residents Recieve Rabies vaccine  United States   \n",
      "3  Albany Residents Recieve Respiratory Syncytial...      Australia   \n",
      "4              Antipolo under threat from Zika Virus    Philippines   \n",
      "5                  Arhus is infested with Bronchitis        Denmark   \n",
      "6                   Arvada is infested with Syphilis  United States   \n",
      "7                                Authorities a Miami  United States   \n",
      "8  Authorities are Worried about the Spread of Br...  United States   \n",
      "9  Authorities are Worried about the Spread of Ch...  United States   \n",
      "\n",
      "          cities  \n",
      "0         Bogotá  \n",
      "1       Sengkang  \n",
      "2        Alameda  \n",
      "3         Albany  \n",
      "4       Antipolo  \n",
      "5          Århus  \n",
      "6         Arvada  \n",
      "7          Miami  \n",
      "8  Silver Spring  \n",
      "9          Hemet  \n"
     ]
    }
   ],
   "source": [
    "headlineCityCountry = {\n",
    "\t'headline': headlineNoLinebreak, \n",
    "\t'countries': headlineCountry,\n",
    "\t'cities': headlineCity\n",
    "}\n",
    "df = pd.DataFrame(headlineCityCountry)\n",
    "print(df.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
